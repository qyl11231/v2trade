有，而且这次重构最容易踩坑的点不少。我们团队按“后端/前端/联调/性能/灰度”把**开发注意事项（必须交代给开发）**整理成一份清单，你可以直接贴到 Jira 任务描述里。

---

## Step 1：后端开发注意事项（高概率坑位）

### 1) **必须断开：BarClosedEvent → 自动算指标**

* BarClosedEvent 订阅只负责 `BarSeriesManager.append()`，**绝不能再触发“查订阅→批量计算→写库”**。
* 否则你们“参数自定义”会导致组合爆炸，资源继续被吃满。

### 2) **evaluate(on-demand) 必须是“纯函数 + 无副作用”**

* 同一 `(indicatorCode, version, params, context)` 多次调用结果一致
* **不能在 evaluate 内写库、不能更新订阅、不能改 BarSeries**（只读输入、返回输出）
* 允许写 `calc_log`（审计/性能），但要避免每次缓存命中都写（会刷爆）

### 3) **缓存键必须冻结且可复现**

* key 一定包含：`indicatorCode + version + pairId + timeframe + asOfBarTime + paramsHash`
* 不能漏 `version` / `paramsHash`，否则会把不同配置的结果混用（最隐蔽的线上 bug）

### 4) **paramsHash 必须稳定**

* Map 的顺序不稳定，hash 前先做：

    * key 排序
    * 数值类型归一（int/long/double）
    * 小数精度统一（BigDecimal 建议转 string）
* 否则同样的参数“看起来一样”，hash 却不一样，缓存命中率会暴跌。

### 5) **BarSeries 窗口长度必须可控（避免内存炸）**

* 现有约定每个周期缓存 365 根 bar（你们原设计）——保留没问题，但要加上限
* 如果允许用户配置 lookback=5000，必须被 schema 限制拦截（否则 ring buffer 扩容会爆内存）

### 6) **min_required_bars / dataQuality 必须实现**

* definition 里已有 `min_required_bars`（你们表设计里有），evaluate 不能忽略
* bars 不足时：`valid=false`、`dataQuality=INSUFFICIENT_BARS`、贡献应为 0（给大脑用时很关键）

### 7) **白名单落库与用户自定义严格隔离**

* `indicator_value` 只能写平台白名单 FACT 指标
* 用户自定义 params 的结果默认不写库（否则 value 表的唯一索引语义会被破坏，且写爆 DB）
* 推荐：返回 `source=ON_DEMAND/CACHE`，不要“偷偷写库”

### 8) **异常处理要“可解释”**

* evaluate 出错时返回结构里要带：

    * `errorCode`（如 PARAM_INVALID / DATA_MISSING / ENGINE_ERROR）
    * `errorMessage`（简短，便于前端 toast）
* calc_log 要记录 stacktrace 摘要（避免 log 过大）

---

## Step 2：前端开发注意事项（UI 一致性 & 联调坑）

### 1) 表单必须由 paramSchema 驱动

* 不允许前端写死 RSI length 之类字段
* schema 要支持：default/min/max/enum/required
* 提交前本地校验：越界直接拦（减少后端压力）

### 2) values 页面新增“按需计算”时的关键交互

* 计算中按钮 loading + 禁用，防重复点击
* 返回必须展示 `source`：DB / CACHE / ON_DEMAND
* 展示 `costMs`（对量化非常有用）

### 3) subscription 页面必须加“说明”

* 避免用户误解“订阅=自动计算”
* 文案建议：

  > “订阅仅用于平台白名单指标的预计算/持久化；自定义参数指标默认按需计算。”

### 4) JSON 展示要可复制

* 量化分析师经常要复制 params/rules，必须提供 copy 按钮

---

## Step 3：联调契约注意事项（接口/字段口径必须冻结）

### 1) EvaluationContext 的时间语义

* `asOfBarTime` 必须是 **bar close time (UTC)**
* 前端不要传本地时间；后端校验 ISO-8601 + Z

### 2) indicatorCode/version 的兼容策略

* 如果 version 为空：后端使用 definition 的 `latestVersion`
* 但返回里必须回显最终使用的 version（便于复盘）

### 3) 返回结构必须统一

* 单个 evaluate 和 batch 结果结构一致
* 必须包含：`indicatorCode/version/value/extraValues/dataQuality/source/costMs/fingerprint`

---

## Step 4：性能注意事项（“谁用谁算”不等于“谁用谁慢”）

### 1) 必须提供 batch evaluate

* 策略大脑一次触发会评估多个因子，不做 batch 会产生 N 次 HTTP/方法调用 overhead

### 2) Caffeine 配置必须可调

* ttl / maxSize 要能通过 yml 改，不要写死
* 生产默认建议：maxSize 按活跃策略规模预估（宁可小一点 + 命中更高）

### 3) calc_log 写入要限流/采样（可选但强烈建议）

* 大量 evaluate 会让 calc_log 变成 IO 热点
* 建议：只记录“实际计算”(cache miss)；或按 indicatorCode 采样

---

## Step 5：灰度与回滚注意事项（上线必备）

### 1) feature flag 必须可回滚

* `indicator.auto-calculate.enabled`（旧链路）
* `indicator.evaluate.enabled`（新链路）
* `indicator.persist.enabled + whitelist`（落库）

### 2) 迁移期“双跑对比”（建议做一段时间）

* 白名单指标可以在灰度期做：

    * DB 结果 vs on-demand 结果一致性抽检
* 不一致要打印差异（避免悄悄漂移）

---

## 总结（交代给开发的一句话）

* **订阅保留只做输入更新**，**计算改为按需 evaluate + 缓存 + batch**；
* **缓存键/paramsHash/时间语义**这三件事必须冻结，否则线上会出现“算错但不报错”的隐蔽 bug；
* **白名单落库与用户自定义严格隔离**，避免写爆 DB；
* 前端**必须 schema 驱动表单**，并展示 `source/costMs` 便于量化排障。

如果你把《指标重构影响范围清单.md》里列的“旧接口调用方”（哪些页面/哪些服务）那段贴出来或我来快速检索，我还能把“每个调用方应该改成单 evaluate 还是 batch evaluate”逐个点名交代。
